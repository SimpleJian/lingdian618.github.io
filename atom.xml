<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title><![CDATA[Just follow your heart]]></title>
  <subtitle><![CDATA[Everything is possible if you have the real passion to what you do]]></subtitle>
  <link href="/atom.xml" rel="self"/>
  <link href="http://lingdian618.github.io/"/>
  <updated>2014-11-04T14:41:17.559Z</updated>
  <id>http://lingdian618.github.io/</id>
  
  <author>
    <name><![CDATA[Lijian]]></name>
    <email><![CDATA[jian.li@nlpr.ia.ac.cn]]></email>
  </author>
  
  <generator uri="http://zespia.tw/hexo/">Hexo</generator>
  
  <entry>
    <title><![CDATA[对KKT条件的理解]]></title>
    <link href="http://lingdian618.github.io/2014/07/05/kkt/"/>
    <id>http://lingdian618.github.io/2014/07/05/kkt/</id>
    <published>2014-07-04T16:00:00.000Z</published>
    <updated>2014-11-03T09:01:25.000Z</updated>
    <content type="html"><![CDATA[<h2 id="带约束的数值优化问题">带约束的数值优化问题</h2>
<p>数值优化问题是在有限维实空间上求单值函数的极值。函数的自变量可能受限制于有限个等式或不等式约束。数值优化问题通常可以写成如下形式：</p>
<span>$$min f(x) \\
s.t. \quad g_i(x)\geq0, h_j(x)=0$$</span>

<p>其中，f(x)是优化目标，x是变量，g(x)是不等式约束，h(x)是等式约束，通常来说，所有的优化问题都可以转化为以上形式。</p>
<h2 id="无约束优化问题的一阶必要性条件">无约束优化问题的一阶必要性条件</h2>
<span>$$\nabla f(x)=0$$</span>


<h2 id="只含等式约束的一阶必要性条件—lagrangian_methond">只含等式约束的一阶必要性条件—lagrangian methond</h2>
<span>$$\nabla f(x) = \sum\lambda_i\nabla h_i(x)$$</span>

<h2 id="一般优化问题的一阶必要性条件—KKT_condition">一般优化问题的一阶必要性条件—KKT condition</h2>
<span>$$\nabla f(x) = \sum\lambda_i\nabla h_i(x) + \sum_{\mu_j \geq 0}\mu_j\nabla g_j(x) \\
\mu_j g_j(x) = 0，\quad \forall j$$</span>


<p>无论优化问题是否有约束，一阶必要性条件在本质上是一样的，如果某点是极值点，那么在该点处一定不存在一个可行的下降（上升）方向使函数值减小（增大），这就是极值点的一阶必要性条件，以下2种情况可以满足该条件：</p>
<ul>
<li>函数在该点的梯度为0，典型的例子是无约束优化问题的一阶必要性条件；</li>
<li>函数在该点的梯度不为0，但由于约束条件的存在，无法沿梯度方向移动来使函数值发生变化。</li>
</ul>
<p>先考虑只有一个等式约束的情况，此时自变量的可行域是一个约束面，假设$ x $最初位于$ x_0 $处，那么此时$ x $的移动方向肯定不能与约束面的法向量方向平行，也不能包含法向量方向的分量，否则沿该方向移动将使得$ x $跳出约束面。所以，当目标函数的梯度方向与约束面在该点的法向量方向平行时，就找不到一个可行的合法的下降方向了（沿梯度方向移动才能下降）。用数学公式表达出来就是$ \nabla f(x) = \lambda \nabla h(x) $，这正是只含一个等式约束条件的一阶必要性条件。</p>
<p>再考虑有多个等式约束的情况，此时自变量可行域为多个约束面的交集，如果目标函数的梯度恰好可以分解为约束面的法向量线性组合，那么，沿目标函数梯度方向的移动将会违背约束条件，所以，含多个等式约束的优化问题的一阶必要性条件为：$ \nabla f(x) = \sum \lambda_i \nabla h_i(x) $</p>
<p>最后考虑含不等式约束的情况，此时的可行域是由等式约束决定的约束面以及由不等式约束决定的区域的交集。要判定 $ x $是否是极值点，可分以下2种情况考虑：</p>
<ol>
<li>$ x $位于区域边界上，此时不等式约束的等号恰好成立，此时的情况可以与等式约束类比，只不过在分解梯度的时候，限定了法向量的方向；</li>
<li>$ x $位于区域内部，此时的不等式约束对可行方向不具约束力，在分解梯度时无需考虑，因此对应的$ \mu_j=0 $，这也解释了为什么要满足互补条件。</li>
</ol>
<p>总结，优化问题的一阶必要性条件的实质是考察梯度条件，这也是为什么叫“一阶”必要性条件的原因。对于带约束的优化问题，只要将约束条件转化为对可行方向的约束，就能够比较直观地理解一阶必要性条件。</p>
]]></content>
    <summary type="html">
    <![CDATA[<h2 id="带约束的数值优化问题">带约束的数值优化问题</h2>
<p>数值优化问题是在有限维实空间上求单值函数的极值。函数的自变量可能受限制于有限个等式或不等式约束。数值优化问题通常可以写成如下形式：</p>
<span>$$min f(x) \\
s.t. \quad ]]>
    </summary>
    
      <category term="Numerical Optimization" scheme="http://lingdian618.github.io/tags/Numerical-Optimization/"/>
    
      <category term="Nonlinear Optimization" scheme="http://lingdian618.github.io/tags/Nonlinear-Optimization/"/>
    
      <category term="KKT" scheme="http://lingdian618.github.io/tags/KKT/"/>
    
      <category term="学习笔记" scheme="http://lingdian618.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[聚类中的关键问题--于剑老师讲座总结]]></title>
    <link href="http://lingdian618.github.io/2014/06/18/cluster/"/>
    <id>http://lingdian618.github.io/2014/06/18/cluster/</id>
    <published>2014-06-17T16:00:00.000Z</published>
    <updated>2014-10-31T14:05:56.000Z</updated>
    <content type="html"><![CDATA[<p>今天下午听了于剑老师关于聚类的讲座，下面简单总结下。</p>
<h2 id="什么是聚类">什么是聚类</h2>
<p>物以类聚，人以群分。这句话比喻同类的东西常聚在一起，志同道合的人相聚成群。关于这个成语还有一个有趣的典故，有兴趣的可以看看<a href="http://baike.baidu.com/view/412596.htm" target="_blank" rel="external">这里</a>。“聚类”这个词应该是取自这个成语，在台湾，“聚类”也叫“分群”。现在的问题是，给你一堆人或者一堆东西，要你把相似的分到同一组，不相似的分到不同的组，这个过程就是聚类。与聚类非常相似的一个概念是分类，一般来说，聚类属于无监督学习，分类属于有监督学习，二者的区别在于是否事先知道类别信息，举个例子，假设对一群人分组，如果事先告诉你要分成2组，一组男的，一组女的，那么这个问题就是分类问题，如果没有相关信息，只要你把这群人分成若干个组就行，那么这个问题就是聚类问题。</p>
<h2 id="为何要聚类">为何要聚类</h2>
<p>聚类能干什么呢？下面是于剑老师ppt上列出来的几点：</p>
<ul>
<li>When studying complex network, people hopes to find the community<br>with intrinsic relations（发现复杂网络中的社群结构）</li>
<li>In image analysis,people hopes to segment an image into<br>homogeneous regions（将图像分割成同质区域）</li>
<li>In text processing, people hopes to find document subsets with the<br>same topic（发现相同主题的文档）</li>
<li>In lossy coding,people hopes to find an code with minimum<br>information loss（在有损编码中，寻找信息丢失最少的编码方式）</li>
<li>In customer behavior analysis, people hopes to find homogeneous<br>customer groups in order to efficiently make an advertisement（对用户分层，从而更有效地打广告）</li>
</ul>
<h2 id="聚类分析的一般流程">聚类分析的一般流程</h2>
<ul>
<li>数据表示和数据预处理，包括数据清洗、特征提取、特征选择</li>
<li>定义相似性，把对象之间的相似性用提取的特征体现出来</li>
<li>聚类，选择某种聚类算法对数据进行划分</li>
<li>性能评估，对聚类结果的好坏进行评价</li>
</ul>
<h2 id="聚类中的关键问题">聚类中的关键问题</h2>
<ul>
<li>相似性的定义。上个世纪60年代，模式识别研究的鼻祖之一，美籍日本学者渡边慧证明了<a href="http://baike.baidu.com/view/815246.htm" target="_blank" rel="external">“丑小鸭定理”</a>。这个定理说的是“丑小鸭与白天鹅之间的区别和两只白天鹅之间的区别一样大”。丑小鸭是白天鹅的幼雏，在画家的眼里，丑小鸭和白天鹅的区别大于两只白天鹅的区别；但是在遗传学家的眼里，丑小鸭与其父亲或母亲的差别小于父母之间的差别。由此引出的一个问题是，事物有没有“本质”？一个苹果，牛顿看到的是它的质量，遗传学家看到的是它的染色体中的DNA序列，美食家关心的是它的味道，画家看到的是它的颜色和形状，孔融还可能关注其大小并从中看出道德因素。这里面没有谁对谁错的问题，所以不可能知道苹果的“本质”是什么。在说到“本质”的时候，充其量说的只是“我认为最重要的特征”，只代表个人的立场，他人并没有赞同的充分理由。所以任何使用“本质”这个词汇所进行的论证都是靠不住的。如果一个哲学家说：“思维是人的本质，计算机不具备这种本质，所以机器不能思维。”这种论证只相当于说：“我认为计算机不能思维，所以计算机不能思维。”这当然不能成为有效的论证。问题就在于世界上还不存在能够判断什么是事物的本质的公认的有效方法。所以没法判断事物之间本质上是否相似，一切相似性定义都是主观的，都是面向具体问题的。</li>
<li>聚类算法的设计。就目前而言，貌似没有什么放之四海皆准的聚类算法，大多数算法都得对数据的分布形式作出一定的假设。在设计聚类算法时，还存在另一个问题，数据在原空间的聚集形态可能跟实际不一致，可能需要将数据转换到另一个空间中，这个问题可以看成是特征处理的问题，也可以在设计聚类算法时考虑。听于老师说，现在很多人做聚类时把特征处理和聚类算法设计合成一个步骤，这样一来可以使特征与算法匹配得更好，从而得到更好的聚类效果。</li>
<li>聚类结果的评估。要对一个聚类结果进行评估，就得有一个所谓的“参考答案”，但是，如果我们已经知道来聚类结果，那么也就没必要再做聚类来，这一矛盾给聚类结果的评估带来不少麻烦。</li>
<li>如何建立聚类分析的公理化系统。这一问题貌似在机器学习中普遍存在，在机器学习中，我们做的很多事情都是基于“经验主义”，而非“理性主义”。要是在机器学习领域能够建立像牛顿力学中那样优美的三大定律公理化系统，那聚类分析的公理化系统应该也不是问题来。</li>
</ul>
]]></content>
    <summary type="html">
    <![CDATA[<p>今天下午听了于剑老师关于聚类的讲座，下面简单总结下。</p>
<h2 id="什么是聚类">什么是聚类</h2>
<p>物以类聚，人以群分。这句话比喻同类的东西常聚在一起，志同道合的人相聚成群。关于这个成语还有一个有趣的典故，有兴趣的可以看看<a href="http://]]>
    </summary>
    
      <category term="clustering" scheme="http://lingdian618.github.io/tags/clustering/"/>
    
      <category term="summary" scheme="http://lingdian618.github.io/tags/summary/"/>
    
      <category term="学习笔记" scheme="http://lingdian618.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[近期总结]]></title>
    <link href="http://lingdian618.github.io/2014/06/16/summary/"/>
    <id>http://lingdian618.github.io/2014/06/16/summary/</id>
    <published>2014-06-15T16:00:00.000Z</published>
    <updated>2014-11-04T14:12:01.000Z</updated>
    <content type="html"><![CDATA[<p>话说自去年入学以来，印象中北京没下过几次雨，但这两天的暴雨提醒了我“北京看海”不是神话。经过昨晚一夜大雨，校园中那条小河水位暴涨，由于小河刚挖成不久，被暴雨这么一冲，“枯水渠”一夜之间变成了“小黄河”。窗外的青蛙在大雨过后也变得异常兴奋，呱呱叫个不停。此刻的我，正坐在宿舍，听着蛙声，准备总结下过去几周的生活。</p>
<p>过去几周，可以说是研究生入学以来最忙碌的一段时间。把时间调回到一个月前，那时的我正忙于参加阿里巴巴的大数据竞赛。在5月初到5月中旬的那2周时间里，每天除了吃饭，睡觉，上课之外，就是做比赛。那段时间确实搞得比较凶，有时甚至不惜破戒12点后才睡觉，即使是这样，早上还经常7点不到就醒了，醒来的第一件事就是，抓过手机看排行榜。照这样的节奏过了大概有2周，然后有一天，上课的时候老师提到大作业的事情，我才意识到一大波考试和大作业即将来袭，而我还一点儿没准备。当时我就有了紧迫感，4门考试，4门大作业，而且时间都集中在5月底到6月初，也就是说3周时间要搞定4门考试和4门大作业，现在想想都有些后怕。由于时间紧迫，所以当天就决定暂时停止比赛，集中精力准备大作业和考试。在接下来的3周时间里，先后搞定了图像检索系统，深圳出租车GPS数据可视化系统以及中文文本自动分类系统3个大作业，其中可视化的那个大作业是组队完成的，队友相当给力。另外，值得庆幸的是，大数据的大作业被老师推迟到了6月底，而且队友说可以直接把他上的“高性能”那门课程的大作业移植过来，所以这也给了我不少喘息之机，否则真忙不过来。</p>
<p>现在该忙的也基本忙完了，比赛也歇了一个多月，今天看了下阿里竞赛的排行榜，都快要掉出前100了，有点跟不上节奏了。不管怎么样，就当做着玩呗。给自己加油！</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>话说自去年入学以来，印象中北京没下过几次雨，但这两天的暴雨提醒了我“北京看海”不是神话。经过昨晚一夜大雨，校园中那条小河水位暴涨，由于小河刚挖成不久，被暴雨这么一冲，“枯水渠”一夜之间变成了“小黄河”。窗外的青蛙在大雨过后也变得异常兴奋，呱呱叫个不停。此刻的我，正坐在宿舍，]]>
    </summary>
    
      <category term="summary" scheme="http://lingdian618.github.io/tags/summary/"/>
    
      <category term="流水帐" scheme="http://lingdian618.github.io/categories/%E6%B5%81%E6%B0%B4%E5%B8%90/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[一个有意思的概率问题]]></title>
    <link href="http://lingdian618.github.io/2014/01/15/an_probability_problem/"/>
    <id>http://lingdian618.github.io/2014/01/15/an_probability_problem/</id>
    <published>2014-01-14T16:00:00.000Z</published>
    <updated>2014-10-31T14:04:53.000Z</updated>
    <content type="html"><![CDATA[<p>在书上看到一个有意思的问题，不知从何说起，举个例子吧。话说临近期末，小明闲来无事，想起了炒股，但他对股市知之甚少，于是他打算请个专家来指导他，为了确保专家质量，他决定对50个“专家”进行考核，选取表现最好的，考核方式如下：让专家们在接下来的连续10天内对某只特定股的涨跌进行独立预测（只预测“涨”或“跌”），10天过后，如果表现最好的专家正确率高于80%，那么就选他，否则说明这批专家太水了，弃之不用。现在的问题是，小明精心选拔出来的表现最好的专家是否可靠？</p>
<p>初看起来小明的选拔方案貌似很合理，首先，不盲从专家，即使是专家也得考核；其次，考核比较严格，连续10天预测，正确率高达80%才有机会，一般人恐怕难以做到；再者，人数众多，滥竽充数者难以胜出。</p>
<p>但事实总是残酷的：通过以上方式选出的专家那是相当的不靠谱！具体分析如下：由于每次预测结果只有2种，所以对一个普通人而已，可以合理假设他在一次预测中正确的概率是0.5，对于连续10次预测，要达到80%以上的正确率，概率大概在0.05左右，可以说是相当低，但是，50个普通人中正确率最高的要达到80%以上的正确率，概率就陡升至93.99%（不信的话自己算去吧），所以说，小明就是找来50个白痴，也很可能有人正确率高于80%（概率高达93.99%）。</p>
<p>这个例子可能有点极端，但确实说明了一定的问题，生活中还有很多类似的问题可以用上述分析过程来解释，比如说：三个臭皮匠赛过诸葛亮；数据挖掘中的Adaboosting方法。</p>
<p>话说小明看到这个后很恼怒（居然选了个白痴），你能帮助小明改进他的选拔方案吗？（小明炒股赢了后不会忘记你的）</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>在书上看到一个有意思的问题，不知从何说起，举个例子吧。话说临近期末，小明闲来无事，想起了炒股，但他对股市知之甚少，于是他打算请个专家来指导他，为了确保专家质量，他决定对50个“专家”进行考核，选取表现最好的，考核方式如下：让专家们在接下来的连续10天内对某只特定股的涨跌进行]]>
    </summary>
    
      <category term="probability" scheme="http://lingdian618.github.io/tags/probability/"/>
    
      <category term="math" scheme="http://lingdian618.github.io/tags/math/"/>
    
      <category term="学习笔记" scheme="http://lingdian618.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[往者不可谏，来者犹可追]]></title>
    <link href="http://lingdian618.github.io/2014/01/01/summary2013/"/>
    <id>http://lingdian618.github.io/2014/01/01/summary2013/</id>
    <published>2013-12-31T16:00:00.000Z</published>
    <updated>2014-11-04T13:58:05.000Z</updated>
    <content type="html"><![CDATA[<p>感冒了，看了一上午电影，睡了一下午，眼看2014年的第一天就要这样宅过去了，但似乎又没有更好的安排，好吧，宅就宅吧，但好歹做点比睡觉更有意义的事情吧，于是写点东西吧。</p>
<p>回首过去的一年，值得记录的各种大事、小事也不多，对我来说称得上大事的可能就是考研、毕业、研究生入学吧。关于考研，印象最深的莫过于选择考中科院的勇气以及准备初试的那段时光了，我的勇气说出来可能有点可笑，“给自己一个创造奇迹的机会”，想起这些，至今仍能感动自我。至于毕业，印象最深的就是拍毕业照和吃散伙饭，遗憾的是没有毕业旅行，写到这里，脑海里隐约浮现出各种无节操的毕业照以及散伙饭时班里几个女生哭成一团的场景。关于研究生入学，其重要性不言而喻，开启了学习生涯新篇章，但由于第一学期集中授课，所以给我的感觉好像是在上大五。其余的各种小事，就重点记录各种人生第一次吧：首先是来北京复试，那次经历创造了多项记录，第一次来北京、第一次坐10+小时的火车、第一次坐卧铺、第一次坐地铁、第一次一个人住宾馆、第一次一个人离家这么远、第一次真正的面试……，这些经历对一些人来说可能微不足道，但对我这样一个大学期间回家不用坐火车的人来说还是值得记录的。然后就是研究生入学以来产生的第一次，比如第一次坐长达6小时的高铁、第一次吃咸的豆腐脑、第一次住单人宿舍、第一次领工资、第一次去长城、第一次坐缆车、第一次滑雪、第一次享用暖气、还有第一次苦逼的抢票……，当时可能没注意，现在回想起来居然有这么多第一次，突然感觉2013没白活。</p>
<p>过去回首完了，该展望未来了。</p>
<p>提到新年计划，说实在的还真没想好，我一向信奉“车到山前必有路，桥到船头自然直”和“人生从来就不是规划出来的，而是一步步走出来的”之类的话，所以一直懒于计划，虽说如此，但还是得有一个大体的方向，方向对了，就不会错得太离谱。下面就列举一些所谓的目标吧：首先，要多读书，这个听起来就不那么靠谱，说实话，之前还真没养成读书这个习惯，都是心血来潮读一读，所以不好给个具体的量化指标，只是希望能养成读书的习惯。其次，学会思考，学会表达，我一直坚信学到的东西只有经过思考才能有更深刻的理解，只有表达出来才能成为自己的东西。然后，要处理好学与思的关系，借用孔子的话来说，“学而不思则罔，思而不学则殆”，我的理解是，学习新知识时要多思考，否则会对学到的东西感到迷惘；遇到问题时不要光思考，可能还要与他人沟通，学习一些解决问题的知识和方法，否则就可能陷于闭门造车的困境。最后，要时刻保持激情，对学习的激情，对生活的激情，只有这样才能保持前行的动力。缺乏激情时不妨想想最可怕的事情吧（比你优秀的人比你更努力）。</p>
<p>最后，我想说的是：2013，去你；2014，走你！</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>感冒了，看了一上午电影，睡了一下午，眼看2014年的第一天就要这样宅过去了，但似乎又没有更好的安排，好吧，宅就宅吧，但好歹做点比睡觉更有意义的事情吧，于是写点东西吧。</p>
<p>回首过去的一年，值得记录的各种大事、小事也不多，对我来说称得上大事的可能就是考研、毕业、研究]]>
    </summary>
    
      <category term="summary" scheme="http://lingdian618.github.io/tags/summary/"/>
    
      <category term="流水帐" scheme="http://lingdian618.github.io/categories/%E6%B5%81%E6%B0%B4%E5%B8%90/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[离散余弦变换(DCT)与离散傅里叶变换(DFT)的关系]]></title>
    <link href="http://lingdian618.github.io/2013/11/03/DCT/"/>
    <id>http://lingdian618.github.io/2013/11/03/DCT/</id>
    <published>2013-11-02T16:00:00.000Z</published>
    <updated>2014-10-31T14:37:50.000Z</updated>
    <content type="html"><![CDATA[<h2 id="理解DCT与DFT之间关系的关键几点">理解DCT与DFT之间关系的关键几点</h2>
<ul>
<li>偶函数的DFT结果只包含余弦项；</li>
<li>对长度有限的数字信号，可以通过偶延拓和周期延拓，然后进行适当平移得到偶函数信号；</li>
<li>偶延拓时使用不同的边界处理方法将得到不同的离散余弦变换；通常按以下方法处理边界：设原信号为{1 2 3 4}，通过偶延拓处理得到{1 2 3 4 4 3 2 1}，然后再进行周期延拓，x(n)=x(n-8)，此时我们发现x(-1)=x(7)=1，将信号右移0.5个单位就得到了偶函数信号。</li>
<li>偶函数的DFT是奇函数，F(n)=0，F(k)=F(2n-k)，因此，虽然DFT结果长度为2n，然而仅需保存前n个即可，这n个数也即DCT变换结果(相差一个常量因子)。</li>
</ul>
<h2 id="实验结果：">实验结果：</h2>
<p>{1 2 3 4}DCT结果为：</p>
<p>{10.000    -3.154    0.000    -0.224}</p>
<p>{1 2 3 4 4 3 2 1}先DFT再进行相位调整(时移0.5)的结果为：</p>
<p>{10.000    -6.309    0.000    -0.448    0.000    0.448    0.000    6.309}</p>
]]></content>
    <summary type="html">
    <![CDATA[<h2 id="理解DCT与DFT之间关系的关键几点">理解DCT与DFT之间关系的关键几点</h2>
<ul>
<li>偶函数的DFT结果只包含余弦项；</li>
<li>对长度有限的数字信号，可以通过偶延拓和周期延拓，然后进行适当平移得到偶函数信号；</li>
<li>偶延拓]]>
    </summary>
    
      <category term="DCT" scheme="http://lingdian618.github.io/tags/DCT/"/>
    
      <category term="DFT" scheme="http://lingdian618.github.io/tags/DFT/"/>
    
      <category term="学习笔记" scheme="http://lingdian618.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[多项式乘法与离散傅里叶变换（DFT）的关系]]></title>
    <link href="http://lingdian618.github.io/2013/10/21/polyDFT/"/>
    <id>http://lingdian618.github.io/2013/10/21/polyDFT/</id>
    <published>2013-10-20T16:00:00.000Z</published>
    <updated>2014-11-04T14:40:36.000Z</updated>
    <content type="html"><![CDATA[<p>离散傅里叶变换是数字信号处理中的重要内容，然而但从公式出发很难获得比较直观的理解。在工程上，我们一般将其理解为，一个长度有限的数字信号可以分解为有限个离散三角函数信号，这样一来DFT的物理意义和相关性质就比较清晰，对DFT的一些性质我们无需从公式出发进行数学推导，可以根据物理意义来理解。比如数字信号在时域的平移可以看成是有限个三角函数信号的平移，而三角函数信号的平移其时就是相位变化，对应的就是是频域的相移。其他一些时域的伸缩变换与频域的伸缩变换也是类似的。但是对于卷积与乘积的关系，确实不好理解（可以看成是数字系统的响应，但还是有点抽象）。今天看完算法导论多项式相关内容，感觉对DFT有了更深的理解，特别是卷积与乘积的关系。</p>
<p>大学期间学Z变换的时候，我就发现Z变换的结果其实就是(1/z)的多项式，多项式的系数可以对应离散的数字信号。我们考虑2个多项式的乘法，<span>$\left(1+x\right) \cdot \left(1+2x\right)=1+3x+2x^2$</span>，通过计算不难发现2点，第一，结果仍是多项式(废话)；第二，结果系数(1, 3, 2)就是原多项式系数(1, 1)和(1, 2)的卷积，这看似巧合，其实正是频域乘积和时域卷积的对应关系。理解完这个后，再来看离散傅里叶变换，你可能想当然的认为差不多，其实差远了。Z变换的结果是多项式，而DFT的结果仍是一个数字序列(一般是复数)，这跟多项式貌似没啥关系呀！其实还是有关系的(没关系我还说个鸟)。对于多项式，我们有2种表示方法，一是系数表示法，二是点值表示法。系数表示法想必大家都清楚，至于点值表示法，具体来讲，就是2个不同点可以确定一条直线(一次多项式)，3点不同点可以确定一条抛物线(二次多项式)，以此类推，我们只需要n+1个不同的点就能唯一确定一个n次多项式(姑且叫多项式采样定理吧)。从信号的角度来理解的话，结论就是，只需n+1个不同采样点就能完全恢复n次多项式信号(是不是很神奇)。DFT的结果其实就能看成一个多项式的点值表示。只是采样点比较奇葩，全是复数，N点DFT的采样点正是方程 <span>$x^N = 1$</span>的N个复数解(复平面中圆心位于原点的单位圆上均匀分布的N条半径)。</p>
<p>如果知道了2个多项式A和B的点值表达，我们能不能求得多项式C=A<em>B的点值表达呢？首先，我们得保证A和B的点值表达是基于相同的采样点，这样 一来对应采样点处的值相乘就能得到C在该点处的值；其次，我们得保证采样点的数目足够多，设A为n次多项式，B为m次多项式，则C=A</em>B为n+m-1次多项式，根据“多项式采样定理”，我们至少需要n+m个采样点。综上所述，如果我们知道A和B在(n+m)个不同时刻的采样值(A和B的采用时间要同步)，那么就能得到C的点值表达。</p>
<p>之前提到，对应一个长为N的离散数字信号，若视其为N-1次多项式的系数，则其DFT就是该多项式的N点表达。我们要是想得到该多项式的L(L &gt; N)点表达呢？不难想到把该信号用0补成长为L的信号，补长后的信号可以看成是L-1次多项式的系数，高次项为0而已。补长后再进行DFT就能得到多项式的L点表达。</p>
<p>现在有2个长度分别为n和m的离散数字信号，该如何通过DFT来计算其卷积呢？首先，2个多项式的系数卷积=多项式乘积的系数；其次，多项式系数DFT=多项式点值表达；再次，只要知道2个多项式的(n+m-1)点表达，就能求得其乘积多项式的点值表达。综上所述，卷积计算方法如下：首先，将2个信号用0补成长度为n+m-1(Why?)；其次，分别计算DFT，得到多项式的点值表达；再次，计算DFT的乘积，得到乘积多项式的点值表达；最后，计算IDFT(逆变换)，得到乘积多项式的系数，也就是原多项式系数的卷积，也即原信号的线性卷积。</p>
<p>注意到我们在利用DFT计算2个信号的卷积时要先把信号进行加0补长为2个信号长度之和，要是不加长或者补0后长度仍不够会出现什么情况？具体分析如下：设原信号长度分别为n和m，补0处理后的长度为N，<span>$\max(n, m) <= n="" <="" n+m-1$<="" span="">，此时进行DFT可得到多项式的N点表达，再做乘法可得乘积多项式的N个采样值，由于<span>$N< n+m-1$</span>，根据“多项式采样定理”知无法恢复<span>$n+m-1$</span>次多项式，我们进行IDFT后得到的只是一个N-1次多项式的系数，并不是乘积多项式系数的卷积，但二者之间并非毫无关联。我们知道DFT是多项式的采样值，而且采样点是方程 x^N = 1 的解，这样一来就有，<span>$x^\left(N+k\right) = x^k$</span>，对于一个高于N-1次的多项式而言，就可以将其高于N-1次的项替换成低次项，并且保证替换后的多项式在采样点处的值不变。替换操作在系数上的变化表现为，高次项的系数被累加到低次项。举个例子，L次多项式系数为[1, 1, 1, 1, 1]，若N=3，则替换后的多项式系数为[2, 2, 1]。</=></span></p>
<p>其实，N点DFT的乘积对应时域信号的N点循环卷积。2个长分别为n和m的信号做N点循环卷积，其结果的DFT等于原信号N点DFT的乘积，当且仅当N &gt;= n+m-1时，循环卷积与线性卷积(通常意义下2个离散信号的卷积)才相等。正因如此，我们可以利用DFT来计算线性卷积，而DFT存在快速算法（FFT），从而大大降低线性卷积的复杂度。</p>
<p>终于完了，写得有些混乱了，也不知道讲清楚没。</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>离散傅里叶变换是数字信号处理中的重要内容，然而但从公式出发很难获得比较直观的理解。在工程上，我们一般将其理解为，一个长度有限的数字信号可以分解为有限个离散三角函数信号，这样一来DFT的物理意义和相关性质就比较清晰，对DFT的一些性质我们无需从公式出发进行数学推导，可以根据物]]>
    </summary>
    
      <category term="Digit image process" scheme="http://lingdian618.github.io/tags/Digit-image-process/"/>
    
      <category term="DFT" scheme="http://lingdian618.github.io/tags/DFT/"/>
    
      <category term="Introduction to algorithm" scheme="http://lingdian618.github.io/tags/Introduction-to-algorithm/"/>
    
      <category term="学习笔记" scheme="http://lingdian618.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[对相关性的理解]]></title>
    <link href="http://lingdian618.github.io/2013/10/14/correlation/"/>
    <id>http://lingdian618.github.io/2013/10/14/correlation/</id>
    <published>2013-10-13T16:00:00.000Z</published>
    <updated>2014-10-31T14:37:26.000Z</updated>
    <content type="html"><![CDATA[<p>何为相关性，根据我的理解，相关性就是某种联系，举几个具体例子，比如说人的身高与体重之间的联系、体重与性别之间的联系、物价与房价之间的联系等等。说到相关性，就不得不提到因果关系，根据我的理解，因果关系应该算是一种比较特殊的相关性，而相关的事物之间不一定具备因果联系。相关性又可以分为线性相关和非线性相关，在这里我要讨论的主要是线性相关。</p>
<p>为何要进行相关性分析？根据马克思主义的观点，事物之间的联系是普遍的，科学研究的主要目的就是发现事物之间的联系，进而达到认识世界、改造世界的目的。这样说有点太大太空了，说点具体的，在数据挖掘等相关研究中，往往需要从海量数据中发现某种规律，从而提取有用信息。在这个过程中，由于数据太多、太杂、还可能有错误，所以在data mining之前必须要进行前期处理，否则就是”garbage in, garbage out”，而且数据量太大还会大大延长算法执行时间。在进行数据前期处理时，就可以对数据进行相关性分析，如果2组数据的相关性很高，就说明存在信息冗余，也许只要其中一组就行，按照这个思想，我们就能剔除很多重复的或者相似的数据。这个例子说明了相关性分析在处理海量数据中的一些应用。其他应用应该还有不少，只是我不知道，或者暂时没想到……</p>
<p>如何进行相关性分析？比如说如何分析人的身高与体重之间的相关性，首先，我们需要数据，数据哪里来，抽样，然后测量样本的身高与体重，这样的话我们就得到了样本数据，用h表示身高数据，w表示体重数据。然后，我们要做的就是分析数组h和w的相关性，那么该如何衡量两个数组之间的相关性呢（线性相关）？一个比较直观的想法是，当一个数组是另一个的常数倍时，这两个数组的相关性应是最高的，那什么时候相关性最低呢？貌似不太直观。嗯，如果我们把这两组数据看成是两个向量呢？oh，yes，I get it！向量平行时，数据相关性最高；向量垂直时相关性最低！数据之间的相关性可以用对应向量之间的夹角来衡量。至于具体的公式，那就去看统计学教程吧！</p>
<p>PS：之前对计算相关系数的那个公式一直不明白怎么来的，为什么要这样定义呢？直到最近我才发现那个公式在形式上很像计算向量之间夹角余弦值……，然后就有了这篇博文。</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>何为相关性，根据我的理解，相关性就是某种联系，举几个具体例子，比如说人的身高与体重之间的联系、体重与性别之间的联系、物价与房价之间的联系等等。说到相关性，就不得不提到因果关系，根据我的理解，因果关系应该算是一种比较特殊的相关性，而相关的事物之间不一定具备因果联系。相关性又可]]>
    </summary>
    
      <category term="similarity" scheme="http://lingdian618.github.io/tags/similarity/"/>
    
      <category term="correlation" scheme="http://lingdian618.github.io/tags/correlation/"/>
    
      <category term="math" scheme="http://lingdian618.github.io/tags/math/"/>
    
      <category term="学习笔记" scheme="http://lingdian618.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
  </entry>
  
</feed>
